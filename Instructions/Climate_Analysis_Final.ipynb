{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Import Dependencies. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "#import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.inspection import inspect\n",
    "from sqlalchemy import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")\n",
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "# We can view all of the classes that automap found.\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2017-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station\n",
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n",
    "#start date = 05/26/2017\n",
    "#end date = 6/3/2018\n",
    "st_date_str = \"2017-08-23\" \n",
    "print(type(st_date_str))\n",
    "st_date = dt.datetime.strptime(st_date_str, '%Y-%m-%d')\n",
    "print(st_date)\n",
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2017-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station\n",
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n",
    "#start date = 05/26/2017\n",
    "#end date = 6/3/2018\n",
    "st_date_str = \"2017-08-23\" \n",
    "print(type(st_date_str))\n",
    "st_date = dt.datetime.strptime(st_date_str, '%Y-%m-%d')\n",
    "print(st_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-23 00:00:00\n",
      "2017-01-10 0.0\n",
      "2017-08-16 0.0\n",
      "2017-07-26 0.0\n",
      "2016-12-30 2.37\n",
      "Count of rows:  2223\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-d93a551e22e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'precip' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the date 1 year ago from today.\n",
    "\n",
    "\n",
    "#Variable created to store date as start_date - 1 year\n",
    "##dateprevyr = dt.date.today() - relativedelta(years=1)\n",
    "dateprevyr = st_date - relativedelta(years=1)\n",
    "print(dateprevyr)\n",
    "##select date, prcp from measurement where date > dateprevyr( current date - 1 yr)\n",
    "\n",
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results.\n",
    "#sel=[\"date\",\"prcp\"]\n",
    "precip_data = session.query(Measurement.date,Measurement.prcp).\\\n",
    "                   filter(Measurement.date > dateprevyr).all()\n",
    "date_lst=list()\n",
    "prcp_lst=list()\n",
    "cnt=0\n",
    "for row in precip_data:\n",
    "    cnt+=1\n",
    "    date_lst.append(row.date)\n",
    "    prcp_lst.append(row.prcp)\n",
    "    if cnt % 500 == 0 :\n",
    "        print(row.date, row.prcp)\n",
    "\n",
    "type(precip_data)\n",
    "print(\"Count of rows: \", str(cnt))\n",
    "precip_data_dict={\"date\":date_lst,\"Precipitation\":prcp_lst}\n",
    "\n",
    "\n",
    "plt.plot(precip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precipitation](Images/precipitation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "\n",
    "precip_data_df = pd.DataFrame(precip_data_dict)\n",
    "precip_data_df = precip_data_df.rename(columns={\"prcp\":\"Precipitation\"})\n",
    "precip_data_df.describe()\n",
    "#print(precip_data_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![describe](Images/describe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "stationsCount = session.query(Station).count()\n",
    "print(f\"Station Count: {stationsCount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "\n",
    "stationCounts = (session.query(Measurement.station, func.count(Measurement.station))\n",
    "                        .group_by(Measurement.station)\n",
    "                        .order_by(func.count(Measurement.station).desc())\n",
    "                        .all())\n",
    "stationCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "#set the most active station\n",
    "stationID = stationCounts[0][0]\n",
    "\n",
    "#query for station name\n",
    "stationName = (session.query(Station.name)\n",
    "                      .filter_by(station = stationID))\n",
    "stationName = stationName[0][0]\n",
    "print(f\"The most active station is {stationID}: {stationName}.\")\n",
    "\n",
    "#query for highest temperature\n",
    "highestTemp = (session.query(Measurement.tobs)\n",
    "                      .filter(Measurement.station == stationID)\n",
    "                      .order_by(Measurement.tobs.desc())\n",
    "                      .first())\n",
    "highestTemp = highestTemp[0]\n",
    "print(f\"The highest temperature recorded there is {highestTemp} degrees Farenheit.\")\n",
    "\n",
    "#query for lowest temperature\n",
    "lowestTemp = (session.query(Measurement.tobs)\n",
    "                     .filter(Measurement.station == stationID)\n",
    "                     .order_by(Measurement.tobs.asc())\n",
    "                     .first())\n",
    "lowestTemp = lowestTemp[0]\n",
    "print(f\"The lowest temperature recorded there is {lowestTemp} degrees Farenheit.\")\n",
    "\n",
    "#query for average temperature\n",
    "avgTemp = (session.query(func.avg(Measurement.tobs))\n",
    "                  .filter(Measurement.station == stationID))\n",
    "avgTemp = '{0:.3}'.format(avgTemp[0][0])\n",
    "print(f\"The average temperature recorded there is {avgTemp} degrees Farenheit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "tempData = (session.query(Measurement.date, Measurement.tobs)\n",
    "                   .filter(Measurement.date > dateprevyr)\n",
    "                   .filter(Measurement.station == stationID)\n",
    "                   .order_by(Measurement.date)\n",
    "                   .all())\n",
    "\n",
    "#convert query object to data frame\n",
    "tempTable = pd.DataFrame(tempData)\n",
    "tempTable = tempTable.set_index('date')\n",
    "\n",
    "#sory by date\n",
    "tempTable = tempTable.sort_index(ascending=True)\n",
    "\n",
    "#histogram plot with pandas\n",
    "tempTable.plot(kind='hist', bins=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precipitation](Images/station-histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n",
    "#set trip dates and previous dates\n",
    "trip = '2019-04-08 to \\n 2019-04-19'\n",
    "tripStartDate = '2017-04-08'\n",
    "tripEndDate = '2017-04-19'\n",
    "\n",
    "#calculate the tmin, tavg, and tmax \n",
    "tripTemps = calc_temps(tripStartDate, tripEndDate)\n",
    "\n",
    "tripTemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n",
    "minTripTemp = tripTemps[0][0]\n",
    "avgTripTemp = tripTemps[0][1]\n",
    "maxTripTemp = tripTemps[0][2]\n",
    "\n",
    "minError = avgTripTemp - minTripTemp\n",
    "maxError = maxTripTemp - avgTripTemp\n",
    "\n",
    "errorBars = np.array([[minError], [maxError]])\n",
    "\n",
    "plt.bar(trip, avgTripTemp, yerr=errorBars, color = 'orangered', alpha = .6)\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.title('Trip Avg Temp')\n",
    "plt.ylabel('Temp (F)')\n",
    "plt.grid(alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n",
    "sel = ([Station.station, \n",
    "        Station.name, \n",
    "        func.sum(Measurement.prcp), \n",
    "        Station.latitude, \n",
    "        Station.longitude, \n",
    "        Station.elevation\n",
    "       ])\n",
    "\n",
    "stationRain = (session.query(*sel)\n",
    "                   .filter(Station.station == Measurement.station)\n",
    "                   .filter(Measurement.date >= tripStartDate)\n",
    "                   .filter(Measurement.date <= tripEndDate)\n",
    "                   .group_by(Station.station)\n",
    "                   .order_by(func.sum(Measurement.prcp).desc())\n",
    "                   .all())\n",
    "\n",
    "#convert query object to data frame\n",
    "stationRainTable = pd.DataFrame(np.array(stationRain))\n",
    "#rename columns\n",
    "stationRainTable = stationRainTable.rename(columns={0: \"Station\", 1: \"Location\", \n",
    "                                                    2: \"Total Precipitation\", 3: \"Latitude\", \n",
    "                                                    4: \"Longitude\", 5: \"Elevation\"})\n",
    "\n",
    "stationRainTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the start and end date for the trip\n",
    "startDate = \"2019-04-08\"\n",
    "endDate = \"2019-04-19\"\n",
    "\n",
    "#calculate trip length\n",
    "startNum = int(startDate[-2:])\n",
    "endNum = int(endDate[-2:])\n",
    "tripLength = endNum - startNum + 1\n",
    "\n",
    "#start date as datetime object\n",
    "startDate = dt.datetime.strptime(startDate, '%Y-%m-%d')\n",
    "#list dates (MM-DD) of trip\n",
    "dateList = [dt.datetime.strftime(startDate + dt.timedelta(days = x), '%m-%d') \n",
    "            for x in range(0, tripLength)]\n",
    "\n",
    "#calculate normals for each date\n",
    "tripNormals = [daily_normals(date) for date in dateList]\n",
    "\n",
    "tripNormals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n",
    "#extract normals into a list of lists\n",
    "tripNormals = [np.array(normal[0]) for normal in tripNormals]\n",
    "\n",
    "#convert normals list into a data frame\n",
    "normalsTable = pd.DataFrame(tripNormals)\n",
    "#add date column\n",
    "normalsTable[\"Date\"] = dateList\n",
    "#set index and rename columns\n",
    "normalsTable = normalsTable.set_index(\"Date\")\n",
    "normalsTable = normalsTable.rename(columns={0: \"Low Temp\", 1: \"Avg Temp\", 2: \"High Temp\"})\n",
    "\n",
    "normalsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n",
    "normalsTable.plot.area(stacked=False, alpha=.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
